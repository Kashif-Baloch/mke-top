# Milwaukee Custard Tracker - Developer Handoff Package

## ğŸ“‹ Project Overview

This is a complete web scraper and API that aggregates "Flavor of the Day" information from 11 frozen custard stands in the Milwaukee area.

**Status:** 100% code complete, ready for deployment
**Your Task:** Deploy to Railway.app and provide live API URL
**Estimated Time:** 1-2 hours
**Technologies:** Node.js, Puppeteer, Express, Cheerio

---

## ğŸ¯ What Needs to Be Done

1. âœ… Set up Node.js project locally
2. âœ… Test that scraper works locally
3. âœ… Deploy to Railway.app (free tier)
4. âœ… Verify all endpoints working
5. âœ… Provide client with live API URL

---

## ğŸ“¦ Project Structure

```
milwaukee-custard-tracker/
â”œâ”€â”€ scraper.js          (Main application - 600+ lines)
â”œâ”€â”€ package.json        (Dependencies configuration)
â”œâ”€â”€ data/
â”‚   â””â”€â”€ flavors.json   (Auto-generated by scraper)
â””â”€â”€ README.md          (This file)
```

---

## ğŸ”§ Technical Details

### Dependencies
- **puppeteer** - Web scraping with headless Chrome
- **cheerio** - HTML parsing
- **express** - REST API server
- **node-cron** - Scheduled scraping (6 AM daily)

### Websites Being Scraped
- Kopp's Frozen Custard (3 locations)
- Murf's Frozen Custard (1 location)
- Culver's (5 locations)
- Leon's Frozen Custard (1 location)
- Gilles Frozen Custard (1 location)

**Total:** 11 locations

### API Endpoints
- `GET /api/health` - Health check
- `GET /api/flavors` - All locations and flavors
- `GET /api/flavors/:id` - Specific location
- `POST /api/scrape` - Trigger manual scrape

---

## ğŸš€ Setup Instructions

### Local Setup

```bash
# Create project
mkdir milwaukee-custard-tracker
cd milwaukee-custard-tracker

# Initialize Node.js
npm init -y

# Install dependencies
npm install puppeteer cheerio node-cron express

# Create data folder
mkdir data

# Copy scraper.js code (provided separately)
# Copy package.json (provided separately)

# Start server
npm start

# Test
curl http://localhost:3000/api/health
curl http://localhost:3000/api/flavors
```

### Deployment to Railway

```bash
# Initialize git
git init
echo "node_modules/
data/
.env
*.log" > .gitignore

# Commit code
git add .
git commit -m "Initial commit"

# Push to GitHub
git remote add origin <GITHUB_URL>
git push -u origin main

# Deploy on Railway
1. Go to railway.app
2. "New Project" â†’ "Deploy from GitHub"
3. Select repository
4. Wait for deploy
5. Settings â†’ Networking â†’ "Generate Domain"
6. Copy domain URL
```

---

## âœ… Verification Checklist

Before delivery, verify:

- [ ] Local server starts without errors
- [ ] Initial scrape completes (see "Found 11 locations" in console)
- [ ] `data/flavors.json` file created
- [ ] Health endpoint returns JSON
- [ ] Flavors endpoint returns custard data
- [ ] Deployed to Railway successfully
- [ ] Live API URL working
- [ ] All 11 locations returning data

---

## ğŸ§ª Testing

### Test Locally
```bash
# Health check
curl http://localhost:3000/api/health

# All flavors
curl http://localhost:3000/api/flavors

# Specific location
curl http://localhost:3000/api/flavors/kopps-greenfield

# Manual scrape
curl -X POST http://localhost:3000/api/scrape
```

### Test Live (after deployment)
```bash
# Replace YOUR_DOMAIN with Railway domain
curl https://YOUR_DOMAIN.up.railway.app/api/health
curl https://YOUR_DOMAIN.up.railway.app/api/flavors
```

---

## ğŸ“Š Expected Output

### Console Output
```
ğŸš€ Milwaukee Custard Tracker API running on port 3000
ğŸ“Š API endpoints:
   GET  /api/flavors - Get all locations and flavors
   ...
ğŸ”„ Running initial scrape...
ğŸ“ Scraping Kopp's...
ğŸ“ Scraping Murf's...
ğŸ“ Scraping Culver's...
âœ… Scraping complete! Found 11 locations
```

### Sample API Response
```json
{
  "timestamp": "2026-01-05T12:00:00.000Z",
  "totalLocations": 11,
  "stands": [
    {
      "id": "kopps-greenfield",
      "name": "Kopp's Frozen Custard",
      "location": "Greenfield",
      "status": "open",
      "flavors": [...]
    }
  ]
}
```

---

## ğŸ†˜ Common Issues & Solutions

### Issue: Puppeteer fails to launch
**Solution:** Already handled in code with proper args

### Issue: Port 3000 in use
**Solution:** Server auto-uses PORT env var on Railway

### Issue: Empty data from scraper
**Solution:** Check Railway logs, may need to increase timeout

### Issue: Railway deployment fails
**Solution:** Ensure package.json has correct start script

---

## ğŸ“ Deliverables

Please provide client with:

1. âœ… Live API URL (e.g., `https://app-name.up.railway.app`)
2. âœ… Confirmation all endpoints working
3. âœ… Screenshot or curl output showing data
4. âœ… Brief note on how to:
   - View logs
   - Trigger manual scrape
   - Redeploy if needed

---

## ğŸ’° Payment Terms

- Payment upon successful deployment
- Must provide working live API URL
- All endpoints must return valid data
- Client must be able to access API

---

## ğŸ“§ Questions?

If you need clarification on any part of the project, please ask before starting work.

**Key Points:**
- All code is complete
- Just needs deployment
- Should take 1-2 hours max
- Railway has free tier (no cost to deploy)

---

## ğŸ¯ Priority

**Timeline:** ASAP
**Complexity:** Low (code is done, just needs deployment)
**Payment:** Upon completion

